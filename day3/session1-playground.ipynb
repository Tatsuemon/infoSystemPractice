{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session1 - playground\n",
    "\n",
    "### Run detection on your own image / 自分が選んだ画像で検出を実行する\n",
    "\n",
    "Set the environment variable\n",
    "<br>\n",
    "環境変数を設定します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS=gcp_credentials/mlpractice2020.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries\n",
    "<br>\n",
    "ライブラリをロードします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load some image. You need to upload an image first (see explanation in cell below) and set the name of the file in the code (variable named `imagefile`) before running the cell.\n",
    "\n",
    "画像を読み込んでください。 セルを実行する前に、まず画像をアップロードし（以下のセルの説明を参照）、コード内で画像ファイルの名前を設定する必要があります（`imagefile`変数）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagefile = \"test.jpg\"\n",
    "\n",
    "with open(imagefile, \"rb\") as fd:\n",
    "    content = fd.read()\n",
    "\n",
    "image = types.Image(content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### HINT: How to upload and use your own image\n",
    "\n",
    "Open Jupyter dashboard (if it is not already open click on the Jupyter logo on the top-left corner of this page). Browse to the folder of the current session: \"day3\". Then use the Upload button on the top-right to upload your image file.\n",
    "\n",
    "#### ヒント：自分の画像をアップロードして使用する方法\n",
    "\n",
    "Jupyterダッシュボードを開く（すでに開いていなければ、このページの左上隅にあるJupyterロゴをクリックする）。 現在のセッションのフォルダ「day3」に移動する。 次に、右上の「Upload」ボタンをクリックして画像ファイルをアップロードする。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the face detection\n",
    "\n",
    "最後に、顔検出を実行します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "faces = client.face_detection(image=image).face_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TASK 1\n",
    "\n",
    "Complete the code below to visualise the detection result.\n",
    "\n",
    "検出結果を視覚化するには、以下のコードを完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = cv2.imread(imagefile)\n",
    "I = I[:,:,[2,1,0]]\n",
    "Ic=I.copy()\n",
    "## ADD HERE THE PLOTTING OF RECTANGLES AROUND FACES\n",
    "\n",
    "plt.imshow(Ic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2\n",
    "\n",
    "The result of face annotations `faces` includes also the detection if the person is smiling. The field `joy_likelihood` (can be accessed using `faces.joy_likelihood`) takes values from 0 (unknown) to 5 (person is very likely to be smiling).\n",
    "\n",
    "Copy the code above to the cell below and than change it so that the color of the rectangle is changed based on the value of `joy_likelihood`.\n",
    "\n",
    "顔認識の結果`faces`には、人物が笑っているかどうかの検出も含まれます。フィールド`joy_likelihood`（`faces.joy_likelihood`でアクセスできます）は 0（未知）から 5（笑っている可能性が非常に高い）までの値をとります。\n",
    "\n",
    "上のコードを下のセルにコピーしてから、変更して、`joy_likelihood`の値に基づいて長方形の色が変わるようにしてください。\n",
    "\n",
    "_Hint_: In function `cv2.rectangle` the fourth parameter sets the color of the rectangle, defined with (red, green, blue) values (0 is lowest, 255 is highest value; e.g. _(255, 0, 0)_ is pure red). You need to change one (or more) of the red/green/blue values depending on the value of `joy_likelihood`.\n",
    "\n",
    "_ヒント_：関数`cv2.rectangle`では、4番目のパラメータは（赤、緑、青）の値で矩形の色を設定します（0が最小値、255が最大値、例えば_(255、0、0)_は純粋な赤）。`joy_likelihood`の値に応じて、赤/緑/青の値の1つ（またはそれ以上）を変更すれば色が変わります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL 1\n",
    "\n",
    "Use OpenCV to plot the position of eyes and mouth on the detected faces. The positions can be read from the detection results. You can use the cv functions cv2.circle and cv2.line. (For usage see e.g. [the OpenCV tutorial](https://docs.opencv.org/3.4.2/dc/da5/tutorial_py_drawing_functions.html))  \n",
    "\n",
    "OpenCVを使用して、検出された顔に目と口の位置をプロットしましょう。検出結果から位置を読み取ることができます。`cv2.circle`や`cv2.line`を使うことができます（使用法については、[OpenCVチュートリアル](https://docs.opencv.org/3.4.2/dc/da5/tutorial_py_drawing_functions.html)などを参照してください）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
