{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of faces in images / 画像中の顔の検出\n",
    "\n",
    "This is our first cloud service example. We will be using the service to detect faces in a photo.\n",
    "<br>\n",
    "Below we explain the code step-by-step.\n",
    "\n",
    "最初の紹介するクラウドサービスの例です。 このサービスを使って写真の中の顔を検出します。\n",
    "<br>\n",
    "以下では、コードを段階的に説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication / 認証\n",
    "\n",
    "We need to set the environment variable for authentication, as explained in the previous notebook. \n",
    "\n",
    "前のセッションで説明したように、認証のため環境変数を設定する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS=gcp_credentials/mlpractice2020.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a test photo / テスト写真を読み込む\n",
    "\n",
    "Let's first take a look at the photo that we will use (\"test.jpg\"). There are several people in it and we want to detect all their faces. \n",
    "<br>\n",
    "We will need the name of the image file several times so we will put in a variable.\n",
    "\n",
    "まずは使用する写真「test.jpg」を見てみましょう。写真には何人かの人が写っています。ここからすべての顔を検出しましょう。\n",
    "<br>\n",
    "画像ファイルの名前が何回も使いますので、変数に入れます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagefile = \"test.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the OpenCV and Matplotlib libraries to open the picture and plot it.\n",
    "\n",
    "OpenCVとMatplotlibライブラリを使って写真を読み込んでプロットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "I = cv2.imread(imagefile)\n",
    "\n",
    "# color image loaded by OpenCV is in BGR mode, but Matplotlib displays in RGB mode. \n",
    "# this command fixes that\n",
    "I = I[:,:,[2,1,0]]\n",
    "\n",
    "# plot the image\n",
    "plt.imshow(I)\n",
    "_=plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running GCP face detection / GCP顔検出の実行\n",
    "\n",
    "First import necessary libraries to work with the Google cloud. \n",
    "<br>\n",
    "(If you use your own local installation, you will need to install the libraries first. You can do it using pip: `pip install google-cloud-vision`)\n",
    "\n",
    "まずGoogleクラウドを使用するために必要なライブラリをインポートします。\n",
    "<br>\n",
    "（自分のPCの環境を使っている場合、最初はライブラリをインストールする必要があります。pipを使えば簡単にインストールすることができます： `pip install google-cloud-vision`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from google.cloud.vision import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GCP methods expect the image data to be in the binary format. \n",
    "<br>\n",
    "Load the image like this:\n",
    "\n",
    "GCPの機能を使うためには画像データがバイナリ形式であることが必要です。\n",
    "<br>\n",
    "画像を以下のようにロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(imagefile, \"rb\") as fd:\n",
    "    content = fd.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an `Image` object with the loaded image data.\n",
    "\n",
    "ロードされた画像データを使って`Image`オブジェクトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = types.Image(content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an ImageAnnotatorClient object.\n",
    "\n",
    "次はImageAnnotatorClientオブジェクトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the central part. Call the `face_detection` method.\n",
    "\n",
    "最後に、中心の部分です。`face_detection`メソッドを呼び出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = client.face_detection(image=image).face_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method takes some time to execute because it sends the image to a Google server and waits to receive the result. \n",
    "\n",
    "上記のメッソドは画像をGoogleサーバーに送信して結果を受け取るのを待つため、実行に時間がかかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FFDDDD; padding: 20pt;\">\n",
    "\n",
    "### Cost and quotas / コストとクオータ\n",
    "\n",
    "_Each time_ you run the above `face_detection` method you are making one call to the Google Cloud and each call is adding to the total cost of using the cloud. Moreover, the Service account key has a quota (limitation on how many calls can be made with this key), to prevent excessive usage by mistake.\n",
    "\n",
    "Therefore, __avoid calling this method repeatedly__. Instead call it just once for each image you need to process (preferably put the call in a separate cell) and afterwards use the variable with the obtained result.\n",
    "\n",
    "上の `face_detection`メソッドを _実行するたびに_ 、Google Cloudのサービスを1回呼び出されます。そのたびにクラウドの使用料金が加算されます。さらに、誤って過剰に使用するのを防ぐために、サービスアカウントキーに対してクオータ（使用量の制限の設定）が設定されています。\n",
    "\n",
    "したがって、このメソッドを __繰り返し呼び出さないでください__ 。代わりに、処理する必要がある画像ごとに1回だけ呼び出してください（できれば、上みたいに、呼び出しを別のセルに入れて）。その後、取得した結果を含む変数を使用できます。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `faces` variable contains the whole result. Let's see how many faces were found.\n",
    "\n",
    "`faces`変数は全体の結果を含みます。顔がいくつ見つかったか見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of faces: {}'.format(len(faces)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`faces` is an array where each element contains the result for one detected face. We will now print the result for the first detected face (`faces[0]`) to see how the full result looks. You will see that it contains a variety of information.\n",
    "<br>\n",
    "(The explanation of all the fields in the result can be found [here](https://cloud.google.com/vision/docs/reference/rpc/google.cloud.vision.v1#google.cloud.vision.v1.FaceAnnotation))\n",
    "\n",
    "`faces`変数は配列です。各要素が一つの検出された顔に対する情報を含みます。結果がどのように見えるかを確認するため、一番目に検出された顔（`faces [0]`）の結果をプリントしましょう。さまざまな情報が含まれていることがわかると思います。\n",
    "<br>\n",
    "（結果のすべてのフィールドの説明を見たかったら[こちらをクリックしてください](https://cloud.google.com/vision/docs/reference/rpc/google.cloud.vision.v1#google.cloud.vision.v1.FaceAnnotation)）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faces[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the result / 結果の視覚化\n",
    "\n",
    "In the result that we printed above you can see that the first printed field is named `bounding_poly`. It contains the position of the rectangle that surrounds the detected face. It has 4 subfields named `vertices`, one for each corner of the rectangle. The order of the `vertices` (corners) is top-left, top-right, bottom-right, bottom-left. Each of the `vertices` contains `x` and `y` values, which give the position of the rectangle corner inside the picture (`x` = number of pixels from left edge, `y` = number of pixels from top of image.)\n",
    "\n",
    "上にプリントした結果では、最初は`bounding_poly`という名前のフィールドがあります。検出された顔を囲む長方形の位置情報が入っています。四角形の各角に一つずつ、`vertices`という名前の4つのサブフィールドがあります。`vertices`（角）の順番は、左上、右上、右下、左下です。 それぞれの `vertices`には`x`と`y`の値があって、それは長方形の角の画像内の位置を表します。（`x`は左端からのピクセル数、`y`は画像の上からのピクセル数）\n",
    "\n",
    "In order to better visualize the result let's plot the image again, with rectangles around all the detected faces. We will use the `bounding_poly` field in the result. \n",
    "<br>\n",
    "The function `rectangle` from the OpenCV library can be used to plot a rectangle inside an image. It needs the coordinates of the top-left and bottom-right corner, which we can get from the first and third `vertices` of each detected face.\n",
    "\n",
    "結果を視覚化するために、画像を表示して、そしてその上に検出された顔を囲む長方形を描きます。長方形の情報は`bounding_poly`フィールドから取ります。\n",
    "<br>\n",
    "OpenCVライブラリの関数`rectangle`は、画像の中に矩形を描きます。左上隅と右下隅の座標が必要ですが、その情報はの顔の1番目と3番目の`vertices`に入っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ic = I.copy()\n",
    "for index,face in enumerate(faces):\n",
    "    pt1 = (face.bounding_poly.vertices[0].x, face.bounding_poly.vertices[0].y)\n",
    "    pt2 = (face.bounding_poly.vertices[2].x, face.bounding_poly.vertices[2].y)\n",
    "    print(\"Face {} coordinates: \".format(index),pt1, pt2)\n",
    "    cv2.rectangle(Ic, pt1, pt2, (0,255,0), 5) ## last 2 parameters are for color (R,G,B) and thickness of line\n",
    "plt.imshow(Ic)\n",
    "_=plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, based on the printed (x,y) coordinates of the detected faces, can you tell which belongs to the women on the left side?\n",
    "\n",
    "ちなみに、上に検出された顔の(x,y)座標をプリントしました。それを見て、何番目の顔が写真の左側にいる女性の顔か、分けりますか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try  it yourself ! / 自分で試そう！\n",
    "\n",
    "The code above was a basic example. Now you can test the face detection on your own images.\n",
    "<br>\n",
    "[Click here](session1-playground.ipynb) to open the notebook with exercise tasks.\n",
    "\n",
    "上記のコードは基本的な例です。 次は自身の画像で顔検出を試しましょう。\n",
    "<br>\n",
    "練習問題のノートブックを開くには[ここをクリックしてください](session1-playground.ipynb)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
