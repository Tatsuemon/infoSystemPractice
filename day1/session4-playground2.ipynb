{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session4 - playground2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the necessary packages\n",
    "- Load the iris dataset\n",
    "- Create the observations `X` and labels `y`\n",
    "\n",
    "\n",
    "- 必要なパッケージをインポートします\n",
    "- アヤメのデータセットを読み込みます\n",
    "- 観測値`X`とラベル`y`を作成します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X has shape: (150, 4)\n",
      "y has shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "iris = np.genfromtxt('iris_data.csv', delimiter=',')\n",
    "\n",
    "X = iris[:,1:]\n",
    "y = iris[:,0]\n",
    "print(\"X has shape:\", X.shape)\n",
    "print(\"y has shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: preparation\n",
    "\n",
    "Copy your code for data preparation from [session4-playground1](session4-playground1.ipynb) (both TASK1 and TASK2) in the cell below and execute it.\n",
    "\n",
    "以下のセルに[session4-playground1](session4-playground1.ipynb)からデータ準備用のコード（TASK1とTASK2の両方）をコピーして、実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 75\n",
      "Testing set size: 75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Testing set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train scaling\n",
    "X_train_raw = X_train \n",
    "X_train = scaler.transform(X_train_raw)\n",
    "\n",
    "# test scaling\n",
    "X_test_raw = X_test\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2\n",
    "- Create and train a linear support vector classifier\n",
    "\n",
    "\n",
    "- 線形サポートベクトル分類器を作成し、トレーニングさせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_SVC = LinearSVC()\n",
    "linear_SVC.fit(X_train, y_train); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3\n",
    "- Predict the labels for the test features\n",
    "\n",
    "\n",
    "- テストデータのラベルを予測する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4\n",
    "- Show the confusion matrix\n",
    "- Compute the accuracy\n",
    "\n",
    "\n",
    "- 混同行列を表示する\n",
    "- 精度を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "A = accuracy_score(y_test,  y_pred)\n",
    "print(\"Accuracy: {:.02f}\".format(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0  0]\n",
      " [ 0 24  4]\n",
      " [ 0  2 20]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL 1\n",
    "- Run the training another time and compare (tip: you can use `Cell -> Run All` from the menu)\n",
    "- Change the proportion of test samples and see the impact on the performance\n",
    "\n",
    "\n",
    "- トレーニングをもう一度実行して、結果を比較します（ヒント：メニューから`Cell -> Run All`を利用できます）\n",
    "- テストサンプルの比率を変更し、パフォーマンスへの影響を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train scaling\n",
    "X_train_raw = X_train \n",
    "X_train = scaler.transform(X_train_raw)\n",
    "\n",
    "# test scaling\n",
    "X_test_raw = X_test\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_SVC.fit(X_train, y_train); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_SVC = LinearSVC()\n",
    "linear_SVC.fit(X_train, y_train); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "A = accuracy_score(y_test,  y_pred)\n",
    "print(\"Accuracy: {:.02f}\".format(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  2 15]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL 2\n",
    "\n",
    "The splitting between training and testing set does not care if there is an \"equal\" number of each flower type in the sets.\n",
    "\n",
    "- Write some code to split the dataset randomly and care about having an equal representation of each flower type (you can start from the code for manually spliting in the main notebook)\n",
    "- Test the average performance of the classifier using this dataset splitting method\n",
    "\n",
    "トレーニングセットとテストセットの分割は、セット内の各花の種類が「等しい」数であるかどうかを考慮していません。\n",
    "\n",
    "- データセットをランダムに分割し、各花の種類の数が同じになるためのコードを実装してください（ヒント：メインのノートブックにある手動の分割のコードを元に開発できます）\n",
    "- このデータセット分割方法を使用して、分類器の平均パフォーマンスを確認してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(x, y, testing_ratio):\n",
    "    print(y)\n",
    "    a_index = np.where(y==0)\n",
    "    a_x = x[a_index]\n",
    "    a_y = y[a_index]\n",
    "    \n",
    "    b_index = np.where(y==1)\n",
    "    b_x = x[b_index]\n",
    "    b_y = y[b_index]\n",
    "    \n",
    "    c_index = np.where(y==2)\n",
    "    c_x = x[c_index]\n",
    "    c_y = y[c_index]\n",
    "\n",
    "    xs = [a_x, b_x, c_x]\n",
    "    ys = [a_y, b_y, c_y]\n",
    "\n",
    "    a_x_train, a_x_test, a_y_train, a_y_test = create_test_train(xs[0], ys[0], testing_ratio)\n",
    "    b_x_train, b_x_test, b_y_train, b_y_test = create_test_train(xs[1], ys[1], testing_ratio)\n",
    "    c_x_train, c_x_test, c_y_train, c_y_test = create_test_train(xs[2], ys[2], testing_ratio)\n",
    "\n",
    "    x_train = np.concatenate([a_x_train, b_x_train, c_x_train], axis=0)\n",
    "    x_test = np.concatenate([a_x_test, b_x_test, c_x_test], axis=0)\n",
    "    y_train = np.concatenate([a_y_train, b_y_train, c_y_train], axis=0)\n",
    "    y_test = np.concatenate([a_y_test, b_y_test, c_y_test], axis=0)\n",
    "\n",
    "    return x_train, x_test,  y_train, y_test\n",
    "    \n",
    "        \n",
    "def create_test_train(x, y, testing_ratio):\n",
    "    number_samples = x.shape[0]\n",
    "    shuffle_index = np.random.permutation(number_samples)\n",
    "    x = x[shuffle_index]\n",
    "    y = y[shuffle_index]\n",
    "    test_samples = int(testing_ratio*number_samples)\n",
    "\n",
    "    x_test = x[:test_samples]\n",
    "    y_test = y[:test_samples]\n",
    "\n",
    "    x_train = x[test_samples:]\n",
    "    y_train = y[test_samples:]\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test  = my_train_test_split(X, y, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train scaling\n",
    "X_train_raw = X_train \n",
    "X_train = scaler.transform(X_train_raw)\n",
    "\n",
    "# test scaling\n",
    "X_test_raw = X_test\n",
    "X_test = scaler.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_SVC.fit(X_train, y_train); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_SVC = LinearSVC()\n",
    "linear_SVC.fit(X_train, y_train); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "A = np.sum(np.diag(CM)) / np.sum(CM)\n",
    "print(\"Accuracy: {:.02f}\".format(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  2 13]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class '0' : P = 1.00 R = 1.00  F = 1.00\n",
      "Class '1' : P = 0.88 R = 1.00  F = 0.94\n",
      "Class '2' : P = 1.00 R = 0.87  F = 0.93\n"
     ]
    }
   ],
   "source": [
    "P = np.diag(CM) / np.sum(CM, axis = 0)\n",
    "R = np.diag(CM) / np.sum(CM, axis = 1)\n",
    "F = 2.0 * R * P / (R + P) # 1 / ((1/P + 1/R) / 2 ) = 2 * R * P / (R + P)\n",
    "for i in range(3):\n",
    "    print(\"Class '{}' : P = {:.02f} R = {:.02f}  F = {:.02f}\".format(i, P[i], R[i], F[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info_system_practice",
   "language": "python",
   "name": "info_system_practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
