{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session2 - playground1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat here the creation of the neural network from session2.\n",
    "\n",
    "以下はsession2でのニューラルネットワークの作成のコードのコピーです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_input = Input(shape = (784,), name='input')\n",
    "fc1 = Dense(128, activation='relu', name='fc1')(vector_input)\n",
    "fc2 = Dense(128, activation='relu', name='fc2')(fc1)\n",
    "output = Dense(10, activation='softmax', name='output')(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_network = Model(vector_input, output, name='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK1\n",
    "- Create a network with one more layer of 64 neurons before the output layer.\n",
    "- Change the activation of the layers from `relu` to `tanh` (hyperbolic tangent - sometimes used as activation, although relu is usually better).\n",
    "- Check the number of trainable parameters.\n",
    "\n",
    "- 出力層の前に、64個のニューロンの層を含むネットワークを作成してください。\n",
    "- すべての層の活性化関数を`relu`から`tanh`に変更してください。（`tanh`は双曲線正接です。活性化関数として使用されることもありますが、通常は`relu`の方がよりいいです。）\n",
    "- 新しいネットワークの訓練可能なパラメータの数を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL 1\n",
    "\n",
    "Create a so-called \"Autoencoder\" neural network. This is a network which has the same number of inputs and outputs, whereas in the middle hidden layer it has less neurons that the number of inputs. For the activation function in the inner (\"hidden\") layers use `relu` and for the output layer `linear`. Set the number of neurons per layer as follows: \n",
    "\n",
    "いわゆる「オートエンコーダ」ニューラルネットワークを作成しましょう。入力と出力の数が同じ、中間の隠れ層のニューロンの数が入力より少ない、という構造を持つネットワークです。内側の（ \"隠れ\"）層の活性化関数には`relu`、出力の層には` linear`を使ってください。層ごとのニューロン数は次のように設定してください。\n",
    "\n",
    "> input -> 128 -> 64 -> 32 -> 64 -> 128 -> output\n",
    "\n",
    "Use `summary` to print out the network structure.\n",
    "\n",
    "ネットワーク構造を`summary`を使ってプリントしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
